{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40f12a1b-16a2-4f37-a9dc-9dd0fa438ac6",
   "metadata": {},
   "source": [
    "# 主题分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e965610b-1c82-4f33-ad78-39658e13083c",
   "metadata": {},
   "source": [
    "### 1. 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09666b41-ddca-460c-aeef-fd8e7e9dcd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "import os\n",
    "import random\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, BertPreTrainedModel\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "from transformers import AutoConfig, AutoTokenizer, BertModel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63804455-6ff8-4f15-bdcd-43819c8b5bc7",
   "metadata": {},
   "source": [
    "### 2. 设置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f933840-355d-4aed-ac20-482ebce9fe33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n"
     ]
    }
   ],
   "source": [
    "max_length = 512                                                     # 最大长度\n",
    "batch_size = 20                                                      # 批量大小\n",
    "learning_rate = 1e-5                                                 # 学习率\n",
    "epoch_num = 5                                                        # epoch数\n",
    "themes = {\"动力\", \"价格\", \"内饰\", \"配置\", \"安全性\", \"外观\", \"操控\", \"油耗\", \"空间\", \"舒适性\"}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'              # 设备(cuda)\n",
    "print(f'using device {device}')\n",
    "\n",
    "checkpoint = \"bert-base-chinese\"                                     # 预训练模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)                # 分词器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b15e9ee-f0ea-474d-9622-694df6630404",
   "metadata": {},
   "source": [
    "### 3. 设置随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07258fdb-2997-4833-a124-a23fddf3c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(12)                                                  # 随机种子"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3894bf-f42c-4ecf-8e29-3614e61d7e3c",
   "metadata": {},
   "source": [
    "### 4. 定义Accuracy函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2eef2ae-f369-415b-9166-413c39a16bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ac(y_true, y_pred):\n",
    "    return metrics.accuracy_score(y_true, y_pred)                    # 正确率 (正确个数/总个数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40e561ec-7bf8-4bcb-af2b-804631f7c17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_try = torch.tensor([1,2,3,4,5,6,7,8,9,0])\n",
    "y_pred_try = torch.tensor([1,2,3,4,5,6,9,9,9,9])\n",
    "Ac(y_true_try, y_pred_try)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69282a56-6e4e-41d7-b033-48edb6e51845",
   "metadata": {},
   "source": [
    "### 5. 定义predict函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ca17e55-31c4-4897-a75d-a2d401c9dd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(output, alpha=0.4):\n",
    "    pred = torch.sigmoid(output)                                     # 转换成概率\n",
    "    zero = torch.zeros_like(pred)                                    \n",
    "    topk = torch.topk(pred, k=2, dim=1, largest=True)[1]             # k个最大概率的index\n",
    "    for i, x in enumerate(topk):\n",
    "        for k in x:                                                  # k个最大概率的index\n",
    "            if pred[i][k] > alpha:\n",
    "                zero[i][k] = 1\n",
    "    return zero.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b66d82a-4032-4632-93e6-431e1c71a709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1320, -0.1254,  0.3443, -0.4519, -0.8888, -0.3526],\n",
       "        [-1.3373,  0.5223, -0.6958, -0.0522, -0.0351,  0.5274],\n",
       "        [-0.8227,  0.5942,  0.6618, -0.0125,  1.4400,  0.7946],\n",
       "        [ 0.8444,  1.2668, -1.0249,  1.2336,  0.8366, -2.0645]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_try = torch.randn(4, 6).to(device)\n",
    "output_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dbdab07-3779-428c-8903-92837fef5263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 1., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(output_try)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c7918a-e386-41cd-9c44-92ffbcc5fad3",
   "metadata": {},
   "source": [
    "### 6. 定义Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69517e05-04bd-45cc-809b-df65466ba5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChnSentiCorp(Dataset):\n",
    "\n",
    "    def __init__(self, data_file):\n",
    "        self.themes = [\"动力\", \"价格\", \"内饰\", \"配置\", \"安全性\", \"外观\", \"操控\", \"油耗\", \"空间\", \"舒适性\"]\n",
    "        self.data = self.load_data(data_file)\n",
    "\n",
    "    def load_data(self, data_file):\n",
    "        theme_sentiment_pattern = re.compile(r'(\\S+?)#(-?\\d+)')\n",
    "        Data = {}\n",
    "\n",
    "        with open(data_file, 'rt', encoding='utf-8') as f:\n",
    "            for idx, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                matches = theme_sentiment_pattern.findall(line)\n",
    "                comment = re.sub(theme_sentiment_pattern, \"\", line).strip()\n",
    "                theme_in_line = [theme for theme, _ in matches]\n",
    "                multi_hot_vector = [1 if theme in theme_in_line else 0 for theme in self.themes]\n",
    "                total_sentiment = sum(int(senti) for _, senti in matches)\n",
    "\n",
    "                if total_sentiment > 0:\n",
    "                    sentiment_label = 2\n",
    "                elif total_sentiment < 0:\n",
    "                    sentiment_label = 0\n",
    "                else:\n",
    "                    sentiment_label = 1\n",
    "\n",
    "                Data[idx] = {\n",
    "                    \"comment\": comment.replace(\" \", \"\"),\n",
    "                    \"themes\": multi_hot_vector,\n",
    "                    \"sentiment\": sentiment_label\n",
    "                }\n",
    "            return Data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32e026a3-22c8-492e-9a3d-273f0fb2965a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training set: 8000\n",
      "length of test set: 2653\n",
      "{'comment': '因为森林人即将换代，这套系统没必要装在一款即将换代的车型上，因为肯定会影响价格。', 'themes': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'sentiment': 1}\n"
     ]
    }
   ],
   "source": [
    "train_data = ChnSentiCorp('data/train.txt')\n",
    "test_data = ChnSentiCorp('data/test.txt')\n",
    "\n",
    "print(f\"length of training set: {len(train_data)}\")\n",
    "print(f\"length of test set: {len(test_data)}\")\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d314853e-4439-4526-9210-3a3d663afae7",
   "metadata": {},
   "source": [
    "### 7. 定义DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1ee3fba-0574-448f-ae7c-935e951e5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch_samples):\n",
    "    batch_sentences, batch_themes_labels, batch_sentiment_labels = [], [], []\n",
    "\n",
    "    for sample in batch_samples:\n",
    "        batch_sentences.append(sample['comment'])\n",
    "        batch_themes_labels.append(sample['themes'])\n",
    "\n",
    "    batch_inputs = tokenizer(\n",
    "        batch_sentences,\n",
    "        max_length=max_length,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'batch_inputs': batch_inputs,\n",
    "        'theme_labels': batch_themes_labels\n",
    "    }\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a95e4637-36e4-4423-bab9-f401710fb9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_inputs': {'input_ids': tensor([[ 101, 6121, 7724,  ..., 3211, 1168,  102],\n",
       "         [ 101, 2769, 4638,  ...,    0,    0,    0],\n",
       "         [ 101,  123, 8026,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 4958, 6444,  ...,    0,    0,    0],\n",
       "         [ 101,  817, 3419,  ...,    0,    0,    0],\n",
       "         [ 101, 2769, 4638,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])},\n",
       " 'theme_labels': [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))\n",
    "#print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a2d0c0-c645-4b7d-811d-d014f2aafc0d",
   "metadata": {},
   "source": [
    "### 8. 定义Bert类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2871e373-adae-4f12-bbc2-f86484a44732",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForMultiTaskLearning(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config, num_themes):\n",
    "        super().__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.num_themes = num_themes\n",
    "        # self.num_sentiments = 3\n",
    "\n",
    "        self.theme_classifier = nn.Linear(self.bert.config.hidden_size, num_themes)               # 多标签主题分类\n",
    "        # self.sentiment_classifier = nn.Linear(self.bert.config.hidden_size, num_sentiments)     # 情感分类\n",
    "\n",
    "        self.theme_loss_fn = nn.BCEWithLogitsLoss()                                               # 损失函数\n",
    "        #self.sentiment_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, batch_inputs, theme_labels=None):\n",
    "        _ = self.bert(**batch_inputs)\n",
    "\n",
    "        theme_logits = self.theme_classifier(_[1])\n",
    "\n",
    "        theme_loss = self.theme_loss_fn(theme_logits, theme_labels.float())\n",
    "\n",
    "        return {\n",
    "            \"theme_loss\": theme_loss,\n",
    "            \"theme_logits\": theme_logits,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce55bd38-7568-4e9c-a3fe-d8591973bb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultiTaskLearning were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['theme_classifier.bias', 'theme_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(checkpoint)\n",
    "model = BertForMultiTaskLearning.from_pretrained(checkpoint, config=config, num_themes=len(themes)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "981ff740-6c1f-400e-9b8e-b02518a2e4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"bert-base-chinese\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.49.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "906b1d23-a99c-4544-9479-126f9cca789b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMultiTaskLearning(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (theme_classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       "  (theme_loss_fn): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f11940",
   "metadata": {},
   "source": [
    "### 9. 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4056a14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\nlp_cw1\\Lib\\site-packages\\transformers\\optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=epoch_num * len(train_dataloader),\n",
    ")\n",
    "\n",
    "writer = SummaryWriter(log_dir='themes_classification_logs' + '/' + time.strftime('%m-%d_%H.%M', time.localtime()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2cd6f5-09e9-4823-859c-7b6a05f0e4dc",
   "metadata": {},
   "source": [
    "### 10. 定义train函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b45a53d1-b2d5-404b-9a3e-d9a1127fe04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_step = 0\n",
    "total_train_loss = 0.\n",
    "best_f1_score = 0.\n",
    "total_test_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6aafd43-513e-405f-95e2-2c27d60754bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, optimizer, lr_scheduler, epoch, total_train_loss, total_train_step):\n",
    "    progress_bar = tqdm(range(len(dataloader)),disable=False)\n",
    "    progress_bar.set_description(f'loss: {0:>7f}')\n",
    "    finish_step_num = epoch * len(dataloader)\n",
    "    true_labels, predictions = [], []\n",
    "    model.train()\n",
    "    for step, batch_data in enumerate(dataloader, start=1):\n",
    "        batch_data = {k: torch.tensor(v).to(device) if isinstance(v, list) else v.to(device) for k, v in batch_data.items()}\n",
    "        theme_labels = batch_data[\"theme_labels\"]\n",
    "        theme_outputs = model(**batch_data)\n",
    "        loss = theme_outputs[\"theme_loss\"]\n",
    "        logits = theme_outputs[\"theme_logits\"]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        pred = predict(logits)\n",
    "        true_labels += theme_labels.cpu().numpy().tolist()\n",
    "        predictions += pred.cpu().numpy().tolist()\n",
    "        #theme_metrics = classification_report(true_labels, predictions, target_names=themes, output_dict=True)\n",
    "\n",
    "\n",
    "        total_train_step +=1\n",
    "        progress_bar.set_description(f'loss: {total_train_loss / (finish_step_num + step):>7f}')\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        if total_train_step % 100 == 0:\n",
    "            accuracy = Ac(true_labels, predictions)\n",
    "            print(\"训练次数:{}，loss:{}\".format(total_train_step, loss.item()))\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "            writer.add_scalar(\"train_accuracy\", accuracy, total_train_step)\n",
    "\n",
    "    return total_train_loss, total_train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77d4cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, epoch):\n",
    "    true_labels, predictions = [], []\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for step, batch_data in enumerate(dataloader, start=1):\n",
    "            batch_data = {k: torch.tensor(v).to(device) if isinstance(v, list) else v.to(device) for k, v in batch_data.items()}\n",
    "            theme_labels = batch_data[\"theme_labels\"]\n",
    "            theme_outputs = model(**batch_data)\n",
    "            loss = theme_outputs[\"theme_loss\"]\n",
    "            logits = theme_outputs[\"theme_logits\"]\n",
    "\n",
    "            pred = predict(logits)\n",
    "\n",
    "            true_labels += theme_labels.cpu().numpy().tolist()\n",
    "            predictions += pred.cpu().numpy().tolist()\n",
    "\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "    metrics = classification_report(true_labels, predictions, target_names=themes, output_dict=True)\n",
    "\n",
    "    macro_precision = metrics[\"macro avg\"][\"precision\"]\n",
    "    macro_recall = metrics[\"macro avg\"][\"recall\"]\n",
    "    macro_f1 = metrics['macro avg']['f1-score']\n",
    "\n",
    "    accuracy = Ac(true_labels, predictions)\n",
    "\n",
    "    print(\"整体测试集上的Loss:{}\".format(total_test_loss))\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss, epoch)\n",
    "    writer.add_scalar(\"test_accuarcy\", accuracy, epoch)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:>0.2f}\\n\")\n",
    "    print(f\"Recall: {macro_recall * 100:>0.2f}\\n\")\n",
    "    print(f\"Precision: {macro_precision * 100:>0.2f}\\n\")\n",
    "    print(f\"Macro-F1: {macro_f1 * 100:>0.2f}\\n\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c0f14d",
   "metadata": {},
   "source": [
    "### 11. 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "387979b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e9a451c99f427b9700deab27b00f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数:100，loss:0.34327030181884766\n",
      "训练次数:200，loss:0.2552517354488373\n",
      "训练次数:300，loss:0.20409934222698212\n",
      "训练次数:400，loss:0.15108773112297058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\nlp_cw1\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "整体测试集上的Loss:19.401519365608692\n",
      "Accuracy: 78.70\n",
      "\n",
      "Recall: 77.41\n",
      "\n",
      "Precision: 90.41\n",
      "\n",
      "Macro-F1: 82.94\n",
      "\n",
      "saving new weights...\n",
      "\n",
      "Epoch 2/5\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a479c74ea5cb4e9c85d717a54f3f29a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数:500，loss:0.1235220655798912\n",
      "训练次数:600，loss:0.14323262870311737\n",
      "训练次数:700，loss:0.09380602836608887\n",
      "训练次数:800，loss:0.13543227314949036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\nlp_cw1\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "整体测试集上的Loss:13.763881355524063\n",
      "Accuracy: 82.40\n",
      "\n",
      "Recall: 85.24\n",
      "\n",
      "Precision: 89.59\n",
      "\n",
      "Macro-F1: 87.22\n",
      "\n",
      "saving new weights...\n",
      "\n",
      "Epoch 3/5\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af340c26a3ea4c4a9bae0e767f5f2315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数:900，loss:0.09821362048387527\n",
      "训练次数:1000，loss:0.1551397144794464\n",
      "训练次数:1100，loss:0.10701768845319748\n",
      "训练次数:1200，loss:0.09039012342691422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\nlp_cw1\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "整体测试集上的Loss:11.97926040366292\n",
      "Accuracy: 83.19\n",
      "\n",
      "Recall: 87.49\n",
      "\n",
      "Precision: 88.49\n",
      "\n",
      "Macro-F1: 87.91\n",
      "\n",
      "saving new weights...\n",
      "\n",
      "Epoch 4/5\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c96acc894b4fcd9e1a3b13b73a1ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数:1300，loss:0.059925761073827744\n",
      "训练次数:1400，loss:0.10005031526088715\n",
      "训练次数:1500，loss:0.06047553941607475\n",
      "训练次数:1600，loss:0.1033034697175026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\nlp_cw1\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "整体测试集上的Loss:11.21520533412695\n",
      "Accuracy: 83.75\n",
      "\n",
      "Recall: 88.33\n",
      "\n",
      "Precision: 88.74\n",
      "\n",
      "Macro-F1: 88.42\n",
      "\n",
      "saving new weights...\n",
      "\n",
      "Epoch 5/5\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ad82ee9c784c38a947b2042d8b1448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数:1700，loss:0.08307182043790817\n",
      "训练次数:1800，loss:0.05157347396016121\n",
      "训练次数:1900，loss:0.058793261647224426\n",
      "训练次数:2000，loss:0.12694351375102997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\nlp_cw1\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "整体测试集上的Loss:11.037318212911487\n",
      "Accuracy: 83.75\n",
      "\n",
      "Recall: 88.90\n",
      "\n",
      "Precision: 88.17\n",
      "\n",
      "Macro-F1: 88.41\n",
      "\n",
      "saving new weights...\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_num):\n",
    "    print(f\"Epoch {epoch + 1}/{epoch_num}\\n\" + 30 * \"-\")\n",
    "    total_train_loss, total_train_step= train_loop(train_dataloader, model, optimizer, lr_scheduler, epoch, total_train_loss, total_train_step)\n",
    "    valid_scores = test_loop(test_dataloader, model, epoch)\n",
    "    macro_f1, micro_f1 = valid_scores['macro avg']['f1-score'], valid_scores['weighted avg']['f1-score']\n",
    "    f1_score = (macro_f1 + micro_f1) / 2\n",
    "    if f1_score > best_f1_score:\n",
    "        best_f1_score = f1_score\n",
    "        print('saving new weights...\\n')\n",
    "        torch.save(\n",
    "            model.state_dict(),\n",
    "            f'epoch_{epoch + 1}_valid_macrof1_{(macro_f1 * 100):0.3f}_microf1_{(micro_f1 * 100):0.3f}_model_weights.bin'\n",
    "        )\n",
    "\n",
    "writer.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc340eb4",
   "metadata": {},
   "source": [
    "### 12. 预测新comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a0a19e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_cw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
